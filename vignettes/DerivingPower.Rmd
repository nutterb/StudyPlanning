<!--
%\VignetteEngine{knitr::knitr}
%\VignetteIndexEntry{Deriving Power Equations}
-->
# Deriving Power Equations

This is a brief summary of deriving statistical power equations based on the 
text of Hogg, McKean, and Craig (Section 5.5, see references).

**Table of Contents**

1. Hypotheses
2. Statistical Conclusions
3. Critical Regions
4. Power
5. References

## 1. Hypotheses
Hypothesis testing is based on the idea of evaluating the likelihood of two 
hypotheses relative to each other.  These hypotheses are based on a parameter, 
$\theta$.

Let us assume the following:

1. $\theta \in \Omega$
2. $X$ is a random variable with density function $f(x; \theta)$
3. $\omega_0 \in \Omega$
4. $\omega_1 \in \Omega$
5. $\omega_0 \cup \omega_1 = \Omega$

We define the hypotheses as
$$H_0: \theta \in \omega_0 \mbox{ vs. } H_1: \theta_1 \in \omega_1$$

$H_0$ is commonly referred to as the _null hypothesis_ and $H_1$ the 
_alternative hypothesis_.  In practice, we often assign the null hypothesis a
known or established values (such as would be typical of our current belief 
about the parameter) and the alternative hypothesis is assigned a value we 
believe to represent a change or difference from the current belief.

## 2. Statistical Conclusions
Based on a sample of data, we may either _Reject_ $H_0$ or we may _Fail to 
Reject_ $H_0$, and our decision rules must be designed so that only one of those
conditions may occur.  Also, based on any given sample, we run the risk of 
making an incorrect decision.

|-------|-------|-------|
| | $H_0$ is TRUE | $H_0$ is FALSE |
| Reject $H_0$ | Type I Error | Correct Decision |
| Fail to Reject $H_0$ | Correct Decision | Type II Error |

\ 

We wish to design statistical tests in a way that minimizes the possibility of
errors.  Since we generally view Type I Error to be more severe, we often 
define the test in a manner that fixes the probability of that error.  We 
label this probability $\alpha$ and also refer to is as the _significance level_
or the test.  The Type II Error, denoted $beta$ is often then derived as a 
function of the distribution function and the sample size.

## 3. Critical Regions
Decision rules can be written in terms of _Critical Regions_ of a probability 
distribution.  If we let $X$ be a random sample with a sample space
$D = space{(X_1, \ldots, X_n)}$, and $\theta$ is a statistic derived from $X$,
we choose a critical region $C$ where $C \subset D$ and 
$$P_\theta[(X_1, \ldots, X_n) \in C] = \alpha$$

## 4. Power
_Statistical Power_ is generally referred to as $1 - \beta$ or the complement 
of the probability of a Type II Error.  In it's most generic form, it is defined

$$\gamma(\theta) = 1 - P_\theta[\mbox{Type II Error}] = P_\theta[(X_1, \ldots, X_n) \in C]$$

where $\theta \in \omega_1$.

To illustrate the derivation of a power equation, we will derive the power 
equation for a test of the mean.  We will assume that $X$ is a 
normally distributed random variable with mean $\mu$ and variance $\sigma^2$.
Let $X_1$, $\ldots$, $X_n$ be a random 
sample of size $n$ from $X$.  Our sample has mean $\bar X$ and variance $S^2$.
To simplify for the purpose of illustration, we will assume a one-sided test where
$$H_0: \mu \leq \mu_0 \mbox{ vs. } H_1: \mu > \mu_0$$

For a chosen $\alpha$, we know we will reject $H_0$ when 
$T = \frac{\bar X - \mu_0}{S/\sqrt{n}} \geq t_{\alpha, n-1}$.

$$\begin{align}
\gamma(\mu) &= P_\mu(\bar X \geq \mu_0 + t_{\alpha, n-1} \cdot S / \sqrt{n})\\
&=P_\mu(\bar X - \mu \geq \mu_0 + t_{\alpha, n-1} \cdot S/\sqrt{n} - \mu)\\
&=P_\mu\Big(\frac{\bar X - \mu}{S/\sqrt{n}} \geq 
        \frac{\mu_0 + t_{\alpha, n-1} \cdot S/\sqrt{n} - \mu}{S/\sqrt{n}}\Big)\\
&=P_\mu\Big(T \geq \frac{\mu_0}{S/\sqrt{n}} + \frac{t_{\alpha, n-1} \cdot S/\sqrt{n}}{S/\sqrt{n}} + 
        \frac{\mu}{S/\sqrt{n}}\Big)\\
&=P_\mu\Big(T \geq \frac{\mu_0 - \mu}{S/\sqrt{n}} + t_{\alpha, n-1} \Big)\\
&=P_\mu\Big(T \geq  t_{\alpha, n-1} + \frac{\mu_0 - \mu}{S/\sqrt{n}}\Big)\\
&=P_\mu\Big(T \geq  t_{\alpha, n-1} + \frac{\sqrt{n}(\mu_0 - \mu)}{S}\Big)
\end{align}$$

Where $t_{\alpha, n-1} + \frac{\sqrt{n}(\mu_0 - \mu)}{S}$ has a non-central T
distribution with noncentrality parameter $\frac{\sqrt{n}(\mu_0 - \mu)}{S}$.

## 5. References
Hogg RV, McKean JW, Craig AT, _Introduction to Mathematical Statistics_,
Pearson Prentice Hall 6th ed., 2005. ISBN: 0-13-008507-3